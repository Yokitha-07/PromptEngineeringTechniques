{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Z8OUAsjWDQmXv3NCSIWc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QPsNSSE4zpdO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import userdata\n",
        "# Replace 'your_file.json' with the actual path to your JSON file\n",
        "try:\n",
        "    df_from_json = pd.read_json('/content/ticket_dataset.json')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'your_file.json' not found. Please upload the file or provide the correct path.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "# 1. Configure the client (using env var or explicitly)\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "_SMISMOJ1ZGH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define your schema using Pydantic\n",
        "class ClassificationOutput(BaseModel):\n",
        "    class_: str\n",
        "    reason: str\n",
        "    confidence: int"
      ],
      "metadata": {
        "id": "nb1ikWhu1H0F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Few Shot Prompt as function\n",
        "# Few-shot Examples Prompting\n",
        "def classify_text_few_shot(text_to_classify, client):\n",
        "    \"\"\"\n",
        "    Classifies text using few-shot prompting with the Gemini model.\n",
        "\n",
        "    Args:\n",
        "        text_to_classify: The text to classify.\n",
        "        client: The Gemini client object.\n",
        "\n",
        "    Returns:\n",
        "        A JSON object containing the classification, reason, and confidence.\n",
        "    \"\"\"\n",
        "    prompt_few_shot = f\"\"\"\n",
        "    Classify the following text into one of these categories: Billing, Account Access, Technical Issue, Feature Request, Spam.\n",
        "    Provide the output as a JSON object with three keys: \"class\", \"reason\", and \"confidence\".\n",
        "\n",
        "    Text: \"The desktop app crashes whenever I click ‘Sync’.\"\n",
        "    Output: {{\"class\": \"Technical Issue\", \"reason\": \"The text describes a software application crashing, indicating a technical problem.\", \"confidence\": 95}}\n",
        "\n",
        "    Text: \"Could you add a dark mode toggle so the interface isn’t so bright at night?\"\n",
        "    Output: {{\"class\": \"Feature Request\", \"reason\": \"The text asks for a new functionality or option to be added to the software.\", \"confidence\": 90}}\n",
        "\n",
        "    Text: \"Limited-time crypto airdrop! Claim your reward now by clicking this link.\"\n",
        "    Output: {{\"class\": \"Spam\", \"reason\": \"The text promotes a suspicious offer and urges clicking a link, characteristic of spam.\", \"confidence\": 98}}\n",
        "\n",
        "    Text: \"{text_to_classify}\"<>\n",
        "    \"\"\"\n",
        "\n",
        "    # 4. Call Gemini via the new SDK with schema enforcement\n",
        "    response_few_shot = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",  # or whichever model you have access to\n",
        "        contents=[prompt_few_shot],\n",
        "        config=types.GenerateContentConfig(\n",
        "            response_mime_type=\"application/json\",\n",
        "            response_schema=ClassificationOutput,\n",
        "            temperature=0.5,\n",
        "            max_output_tokens=5000,\n",
        "        ),\n",
        "    )\n",
        "    return response_few_shot.text\n",
        "\n",
        "# Example usage of the function:\n",
        "text_to_classify_example = \"Payment failed twice today during renewal, but my card is valid. Why isn't it going through?\"\n",
        "classification_output = classify_text_few_shot(text_to_classify_example, client)\n",
        "print(\"\\nFew-shot Examples Prompting Function Output:\")\n",
        "print(classification_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RQ3UcEXqwZY",
        "outputId": "f4233a8c-7fb5-472b-8281-93707f31d3d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Few-shot Examples Prompting Function Output:\n",
            "{\"class_\": \"Billing\", \"reason\": \"The text describes a problem with a payment failing during a renewal process, which is directly related to billing and financial transactions.\", \"confidence\": 97}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_classification_accuracy(file_path, client):\n",
        "    \"\"\"\n",
        "    Loads a dataset from a JSON file, classifies each text entry using few-shot prompting,\n",
        "    and calculates the accuracy compared to the original labels.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the JSON dataset file.\n",
        "        client: The Gemini client object.\n",
        "\n",
        "    Returns:\n",
        "        The accuracy score (float).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            dataset = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file not found at {file_path}\")\n",
        "        return None\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for i,entry in enumerate(dataset):\n",
        "        text = entry['text']\n",
        "        true_label = entry['class']\n",
        "\n",
        "        # Classify the text using the few-shot function\n",
        "        classification_output_str = classify_text_few_shot(text, client)\n",
        "\n",
        "        try:\n",
        "            # Parse the JSON output from the classification function\n",
        "            classification_output = json.loads(classification_output_str)\n",
        "            predicted_label = classification_output.get('class_') # Use 'class_' to match Pydantic schema\n",
        "            print(f\" Predicted : {predicted_label} - Actual : {true_label}\")\n",
        "            if predicted_label:\n",
        "                predictions.append(predicted_label)\n",
        "                true_labels.append(true_label)\n",
        "            else:\n",
        "                print(f\"Warning: Could not extract predicted class for text: {text}\")\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error decoding JSON output for text: {text}\")\n",
        "\n",
        "        time.sleep(30)\n",
        "\n",
        "\n",
        "    if not predictions:\n",
        "        print(\"No valid predictions were made.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Example usage:\n",
        "dataset_file = '/content/ticket_dataset.json'  # Replace with the actual path to your dataset\n",
        "accuracy = evaluate_classification_accuracy(dataset_file, client)\n",
        "\n",
        "if accuracy is not None:\n",
        "    print(f\"\\nClassification Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPEkWexE7l3k",
        "outputId": "d0736cc3-e310-4719-e7e3-136133ce1e15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Predicted : Billing - Actual : Billing\n",
            " Predicted : Account Access - Actual : Account Access\n",
            " Predicted : Technical Issue - Actual : Technical Issue\n",
            " Predicted : Feature Request - Actual : Feature Request\n",
            " Predicted : Spam - Actual : Spam\n",
            " Predicted : Technical Issue - Actual : Technical Issue\n",
            " Predicted : Billing - Actual : Billing\n",
            " Predicted : Feature Request - Actual : Feature Request\n",
            " Predicted : Account Access - Actual : Account Access\n",
            " Predicted : Billing - Actual : Billing\n",
            " Predicted : Account Access - Actual : Account Access\n",
            " Predicted : Technical Issue - Actual : Technical Issue\n",
            " Predicted : Feature Request - Actual : Feature Request\n",
            " Predicted : Account Access - Actual : Account Access\n",
            " Predicted : Billing - Actual : Billing\n",
            " Predicted : Spam - Actual : Spam\n",
            " Predicted : Feature Request - Actual : Feature Request\n",
            " Predicted : Technical Issue - Actual : Technical Issue\n",
            " Predicted : Account Access - Actual : Account Access\n",
            " Predicted : Billing - Actual : Billing\n",
            "\n",
            "Classification Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}